---
layout: single
title: "[KAFKA] Kafka 구조 및 이론"
excerpt: "KAFKA - Broker, Topic, Partition etc."

categories:
  - tech
tags:
  - [tech, kafka, zookeeper]

toc: false
toc_sticky: true

date: 2022-12-19
last_modified_at: 2022-12-19
---
# 카프카 

- 출처 : https://always-kimkim.tistory.com/entry/kafka101-configuration-bootstrap-servers

## 카프카 브로커

- 브로커 : 프로듀서로부터 메시지를 전달받고, 다시 이를 컨슈머로 전달하는 역할을 담당.

![kafka_s01](./../../images/tech/kafka_s_01.png)

## Kafka Message

- 카프카의 메시지는 Key(키)와 Value(값)로 구성.
- 메시지의 키는 해당 메시지가 카프카 브로커 내부에 저장될 때, 저장되는 위치와 관련된 요소. 
- 프로듀서가 메시지를 브로커로 전달할 때, 프로듀서 내부의 파티셔너(Partitioner)가 저장 위치를 결정하는데, 이때 키의 값을 이용하여 연산하고 그 결과에 따라 저장되는 위치를 결정.
- 메시지의 값은 메시지가 전달하고자 하는 내용물을 의미. 
- 값은 단순한 문자열이 될 수도 있고, JSON이나 특정 객체도 가능. 
- 브로커를 통해 메시지가 발행되거나 소비될 때, 메시지 전체가 직렬화/역직렬화되기 때문에 다양한 타입의 값을 저장 및 전달가능.
- 메시지의 키와 값은 다양한 타입이 될 수 있지만, 특정한 구조인 스키마(schema)를 가짐. 
- 카프카 메시지의 스키마는 데이터베이스의 테이블 스키마와 유사한 개념으로 프로듀서가 발행하고 컨슈머가 소비할 때 메시지를 적절하게 처리하기 위해 필요. 

  >
  > 예를 들어, 프로듀서가 내용(값)이 JSON 형태인 메시지를 발행할 때,   
  > 해당 메시지를 소비하는 컨슈머는 프로듀서가 생산한 JSON의 구조를  
  > 예상하고, 그에 맞게 메시지를 처리하려고 합니다.   
  > 이때 만약 프로듀서와 컨슈머가 메시지에 대한 서로 다른 스키마를   
  > 가지고 있다면, 정상적인 처리를 할 수 없습니다. 이처럼 스키마는  
  > 카프카 개발, 운영에서 굉장히 중요한 역할을 담당.
  >

## Kafka Topic

 - 메시지를 구분하는 논리적인 단위이자 메시지 흐름의 단위.
 - 동일한 토픽의 메시지들은 논리적으로 같은 문맥(context)을 가집니다. 

  > 예를 들어, 주문에 관한 내용을 담고 있는 메시지를 발행하고, 소비하기  
  > 위해서 우리는 order라는 토픽을 생성하고 이 토픽을 기준으로   
  > 메시지를 발행, 소비할 수 있습니다.

- 토픽을 설계할 때는 메시지의 논리적인 구분을 명확하게 해야함.

## Kafka Partition

- 논리적인 단위인 카프카 토픽을 기준으로 발행되는 메시지들은 브로커 내부의 물리적인 단위인 카프카 파티션(Partition)으로 나뉨. 
- 모든 토픽은 각각 대응하는 하나 이상의 파티션이 브로커에 구성되고, 발행되는 토픽 메시지들은 파티션들에 나뉘어 저장됨. 

![kafka_s02](./../../images/tech/kafka_s_02.png)

- 분산 처리를 통한 성능 향상을 위해 하나의 토픽에 대하여 여러 파티션을 구성. 
- 카프카는 하나의 토픽에 대해 여러 프로듀서가 발행할 수 있고, 여러 컨슈머가 구독하기 때문에 토픽을 하나의 파티션으로 구성하면, 무수한 발행-구독 요청을 하나의 파티션이 처리해야 함. 
- 일반적으로 2개 이상의 파티션을 서로 다른 브로커에 병렬 구성하여 요청의 부하를 분산시켜 해당 토픽에 관한 처리성능을 향상. 
- **하나의 파티션 내에서는 메시지 순서가 보장.** 파티션은 메시지 순서 보장의 단위로, 각 파티션의 메시지는 발행되는 순서대로 구독가능. 
- **하나의 토픽이 여러 파티션으로 구성되는 경우, 토픽 단위의 메시지 순서는 보장불가. 이는 파티션 내부에서의 순서는 보장되지만 파티션 간의 순서는 보장되지 않기 때문.**

## Partition Replica

- 하나의 토픽은 하나 이상의 파티션으로 구성. 
- 서비스 안정성과 장애 수용(Fault-Tolerance)에 관한 요소로 파티션의 복제(Replica) 기능 제공.
- 하나의 파티션은 1개의 리더 레플리카와 그 외 0개 이상의 팔로어 레플리카로 구성. 
  - 리더 레플리카는 파티션의 모든 쓰기, 읽기 작업을 담당. 
  - 팔로어 레플리카는 리더 레플리카로 쓰인 메시지들을 그대로 복제하고, 만약 리더 레플리카에 장애가 발생하는 경우, 리더 자리를 승계받을 준비.

- ISR(In-Sync Replica) : 리더 레플리카의 메시지를 적절하게 복제하여 리더 레플리카와 동기화된 레플리카들의 그룹.

![kafka_s03](./../../images/tech/kafka_s_03.jpg)

 - 파티션의 레플리카 수는 복제 계수(Replication factor)를 통해 결정. 
  - 복제 계수가 1이라면 파티션은 리더 레플리카로만 구성. 
  - 복제 계수가 2개 이상이라면 해당 파티션은 1개의 리더 레플리카와 1개 이상의 팔로어 레플리카로 구성. 
    - 이 경우 모든 레플리카들은 서로 다른 브로커에 구성. 
    - 같은 파티션의 레플리카가 동일한 브로커에 구성되는 경우에는 에러발생. 

 - 파티션의 레플리카들은 언제 발생할지 모르는 장애에 대비하여 데이터 유실을 방지하고, 지속적인 서비스를 제공하기 위해 구성. 

## Kafka Broker

- Broker는 프로듀서와 컨슈머 사이에서 메시지를 중계.일반적으로 '카프카'라고 불리는 시스템을 칭함. 
- 프로듀서와 컨슈머는 별도의 애플리케이션으로 구성되는 반면, 브로커는 카프카 자체.
- '카프카를 구성한다' 혹은 '카프카를 통해 메시지를 전달한다'에서 카프카는 브로커를 의미. 

### Kafka (Broker) 클러스터 구성

- 브로커는 한 대 이상의 노드로 클러스터를 구성할 수 있지만 **브로커들로만 클러스터를 구성불가.**
- **브로커의 여러 가지 메타 정보를 저장 관리해주는 주키퍼(Zookeeper)가 필요하기 때문.**  
- 카프카를 구성할 때는 한 대 이상의 주키퍼로 구성된 주키퍼 클러스터와 한 대 이상의 브로커로 구성된 브로커(=카프카) 클러스터로 구성.
  - 일반적인 최소 사양으로 주키퍼 3, 카프카 3으로 구성.

### Kafka의 구조적인 특징

- 각 브로커들이 클러스터 전체 데이터의 일부분을 저장.
  - 논리적인 단위인 토픽은 메시지 저장의 단위인 파티션으로 쪼개져 구성. 
  - 파티션은 복제(replication)를 통해 여러 브로커에 산개되어 구성.

![kafka_s04](./../../images/tech/kafka_s_04.jpg)

  - 토픽 파티션이 브로커에 산개되어 있는 모습. 
  - 프로듀서가 topic1-partition1에 메시지를 전달하려면 해당 리더 파티션이 위치한 1번 브로커에 메시지를 전달해야 함
  - (출처 : https://www.confluent.io/blog/hands-free-kafka-replication-a-lesson-in-operational-simplicity/ )

 - 개별 브로커는 클러스터 전체 데이터를 가지고 있지 않음. 
 - 그렇기 때문에 클라이언트는 브로커와 연결하여 브로커 내부의 자원에 접근하기 위해, 클라이언트가 접근하고자 하는 자원의 위치가 필요. 

  > 위 그림을 예로, 프로듀서가 토픽 1의 파티션 1(topic1-partition1)에   
  > 메시지를 발행하려면 프로듀서는 해당 토픽 파티션이 전체 브로커  
  > 클러스터 중 몇 번 브로커에 위치하는 지 알아야합니다.   
  > 그래서 카프카는 클라이언트가 카프카와 처음 연결될 때, 자원들의   
  > 메타데이터를 공유하기 위해 bootstrap.servers 설정을 요구.

### bootstrap.servers 설정

 - bootstrap.servers 설정은 클라이언트가 접근하는 토픽 파티션의 메타데이터를 요청하기 위한 설정.
 - 브로커의 호스트/포트 정보의 리스트 형태의 값의 형태.
 - 설정 값의 호스트 정보를 기준으로 순차적으로 메타데이터를 요청하고, 만약 성공할 경우에는 그 메타데이터를 이용. 

  > 예를 들어, bootstrap.servers=broker1:9092,broker2:9092,broker3:9092로  
  > 설정되어 있다면 클라이언트는 broker1:9092 부터 메타데이터를 요청하고  
  > 해당 요청이 실패하면 broker2:9092로 요청합니다.

- 전체 카프카 리스트가 아닌 호스트 하나만 입력해 사용할 수 있지만, 이 방법을 추천하지는 않음. 
  - 극단적인 예로 100개의 브로커가 구동 중인데, 클라이언트가 bootstrap.servers 설정에 1개의 브로커 호스트만 입력하고, 이 때 해당 브로커가 어떤 이유(비정상 중단 혹은 롤링 리스타트 등)에서 잠시 중단된다면 해당 클라이언트는 정말 운이 나쁘게도 그 카프카 클러스터와 연결할 수 없게됨.
- 카프카 클러스터는 살아있는 상태이지만 해당 호스트만 장애가 발생하는 경우 접속이 불가하기 때문에, 리스트 전체를 입력하는 것을 권장. 
  - 주어진 리스트의 서버 중 하나에서 장애가 발생할 경우 클라이언트는 자동으로 다른 서버로 재접속을 시도하기 때문에 사용자 프로그램에서는 문제없이 사용가능.

### 메타데이터 요청 과정

- 클라이언트는 bootstrap.servers 설정에 입력된 브로커 호스트 정보를 이용하여 메타데이터를 요청합니다. 
  - 1. 클라이언트가 브로커와 연결
  - 2. 연결 성공 시, 클러스터에 등록된 모든 브로커와 토픽, 파티션의 메타데이터 전송
  - 3. 클라이언트는 메타데이터에서 토픽 파티션의 위치(브로커)를 찾음
  - 4. 클라이언트는 해당 브로커로 요청

- 메타데이터 요청 과정을 통해 클라이언트가 토픽 파티션의 위치를 알게되면, 이 후 Pub/Sub 과정을 진행.
- 메타데이터는 클라이언트가 브로커에 처음 접근할 때와 주기적으로 갱신할 때 요청, 단, 다음 2가지 상황이 발생하면 클라이언트가 브로커에 다시 메타데이터를 요청.
  - 현재 접근하고 있는 브로커가 비정상인 경우 : 비정상 중단 혹은 롤링 리스타트 등
  - 클라이언트가 접근하고 있던 리더 토픽 파티션의 위치가 변경된 경우 : Partition Re-assign

### Zookeeper

- 아파치 프로젝트 중 하나로 하둡 에코 시스템을 구성. 
- 주 역할은 분산 시스템의 메타 정보를 관리하고, 필요시에는 분산 시스템의 마스터를 선출. 

 > 예를 들면, 카프카 클러스터를 구성하면 주키퍼에는 카프카 클러스터의  
 > 식별 정보부터 현재 살아있는 브로커 정보, 나아가 권한 정보 등이 저장.  
 > 또한, 카프카 브로커들 중 일종의 지휘자 역할을 하는 컨트롤러(Controller)   
 > 브로커를 뽑는 역할을 담당.

- 주키퍼는 디렉터리 형태로 데이터를 저장, 관리. 
- 카프카의 메타 정보는 클러스터 구성할 때, 주키퍼 연결 설정(zookeeper.connect)에서 지정된 디렉토리 하위에 저장. 따라서 동일한 카프카 클러스터는 주키퍼 연결 설정에서 동일한 디렉토리 경로를 가지며, 하나의 주키퍼 클러스터에 여러 카프카 클러스터가 동시에 구성가능. 

## Peer-to-Peer 구조

- 카프카 클러스터는 모든 브로커가 클라이언트의 요청을 처리할 수 있는 Peer-to-Peer(p2p) 구조. 
- 클라이언트와 카프카 간 메타 데이터를 전달하는 과정이 있기 때문에 p2p 구조가 가능.
- 단, 브로커는 p2p 구조인 반면, 실제로 메시지를 전달받고 저장하는 단위인 파티션은 리더와 팔로워로 나뉘어 작업을 처리. 

![kafka_s05](./../../images/tech/kafka_s_05.jpg)

- 하나의 토픽이라도 리더 파티션의 위치에 따라 여러 브로커가 요청 받을 수 있습니다.

## 주요 브로커 설정

- 브로커는 여러 환경에 따라 다양한 설정을 할 수 있으며 이러한 설정의 대부분은 기본값이 제공. 
- 따라서 별도로 설정해주지 않아도 되지만 다음 3가지 설정은 반드시 설정필요.

  - broker.id
  - log.dirs
  - zookeeper.connect

 - 1. broker.id  
  - 같은 카프카 클러스터에서 현재 브로커를 식별하기 위한 숫자.
  - 다른 브로커와 다른 숫자를 설정해야 하며 일반적으로는 0 혹은 1부터 순차적으로 설정.

 - 2. log.dirs 
  - 브로커가 프로듀서로부터 받는 메시지들을 저장할 위치 경로를 지정하는 설정. 
  - 기본 값은  /tmp/kafka-logs. 
    - 기본 값이 /tmp/ 하위에 지정되기 때문에 OS 설정에 따라 임의로 삭제될 수 있으므로 별도의 위치로 지정필요.

 - 3. zookeeper.connect
  - 카프카 클러스터의 메타 정보를 저장할 주키퍼에 관한 호스트 연결 정보. 
  - 호스트 연결 정보는 hostname:port로 구성되며, 동일한 주키퍼 클러스터의 여러 노드를 ', '로 구분한 문자열로 지정. 
    - 'zookeeper01:2181, zookeeper02:2181'와 같이 설정. 
    - 주키퍼 내부의 저장 위치를 함께 설정할 경우 'zookeeper01:2181, zookeeper02:2181/my/path'와 같이 설정.

 - 이 외에도 설정
  - advertised.listeners : 클라이언트가 브로커를 바라볼 때의 브로커 호스트 정보.
  - auto.create.topics.enable : 클라이언트가 특정 토픽으로 요청했을 경우 자동 생성 여부. (기본값 true)
  - offsets.topic.replication.factor : 오프셋 토픽의 복제 계수. (기본값 3)

    > 브로커는 하나 이상의 리스너(listener)를 통해 외부 요청을 받습니다.  
    > advertised.listeners 는 클라이언트가 브로커에게 요청할 때, 클라이언트  
    > 입장에서 브로커를 찾을 수 있는 호스트 정보를 설정합니다. 이 설정은  
    > 초기 메타 데이터 전달 과정에서 클라이언트로 전달되고,   
    > 이 정보를 바탕으로 클라이언트가 브로커로 요청합니다. 여기서 중요한 것은  
    > 클라이언트와 브로커의 네트워크 환경이 다를 경우, 클라이언트가  
    > 브로커를 찾을 수 있도록 설정해줘야 한다는 것입니다.

![kafka_s06](./../../images/tech/kafka_s_06.jpg)

- 도커 네트워크와 로컬 호스트 네트워크 간 별도의 리스너를 구성했을 때, advertised.listeners 설정을 클라이언트가 브로커를 찾을 수 있는 호스트 정보로 설정필요. (출처 : https://docs.confluent.io/current/kafka/multi-node.html)

- auto.create.topics.enable 는 운영 과정에서 중요한 설정입니다. 실제 상용 환경에서 브로커는 무수히 많은 클라이언트와 맞이하게 됩니다. 그렇게 때문에 적절한 토픽의 관리가 필요한데, 만약 이 설정을 true로 설정하면 클라이언트의 요청에 따라 토픽이 지속적으로 생성됩니다. 이는 운영 상에 큰 골칫거리가 될 수 있겠습니다. 

 - offset.topic.replication.factor 는 개발 환경 구성에서 많이 부각되는 설정입니다. 오프셋(offset) 토픽의 복제 계수에 관한 설정인데, 만약 브로커를 1대로 구성하게 되면 기본값이 3과 충돌하여 브로커가 실행되지 않습니다. 복제 파티션들은 같은 브로커에 존재할 수 없기 때문입니다. 그러므로 개발 환경에서 1대로 구성할 경우에는 꼭 해당 설정을 1로 설정해야 합니다.

## 브로커 내부 동작 요소

 - 카프카 브로커는 프로듀서로부터 메시지를 발행받아 이를 저장하고, 컨슈머로 전달하는 과정을 위해 브로커 내부에는 다양한 동작 요소들이 존재.

### Controller

 - 하나의 클러스터에서 하나의 브로커에 부여되는 역할로, 지휘자와 같은 역할. 
 - 컨트롤러는 브로커들의 생존 여부(liveness)를 체크. 만약 임의의 브로커가 중단되었을 경우, 해당 브로커에 있었던 리더 파티션을 탈락시키고 다른 팔로워 파티션들 중 하나를 리더로 뽑습니다(leader election). 이 과정은 카프카의 실패 극복(failover) 전략 중 중요한 부분. 
 - 컨트롤러가 중단되는 경우에는 주키퍼가 이를 감지하여 새로운 컨트롤러를 선출.

![kafka_s07](./../../images/tech/kafka_s_07.jpg)

- 브로커가 종료될 때, 컨트롤러를 통한 복제 파티션의 리더 재선출 과정. 컨트롤러는 변경된 리더 파티션 정보를 주키퍼에 저장하고, 리더 파티션을 조정 (출처 : https://www.slideshare.net/ConfluentInc/a-deep-dive-into-kafka-controller)

### 메시지 저장과 메시지 파일 관리

- 브로커는 프로듀서로부터 전달되는 메시지를 로그(log) 자료구조 형태로 디스크에 저장. 
- 로그 자료구조는 새로운 쓰기 작업이 중간에 삽입되지 않고 오로지 끝에서만 되는 append-only 특징. 일반적으로
- 쓰기 작업이 끝에서만 이뤄지므로 브로커에 이미 쓰여진 메시지(로그)는 변경불가.

![kafka_s08](./../../images/tech/kafka_s_03.png)

- 브로커 파티션에 메시지를 쓰고, 읽는 모습. 각 네모 칸은 메시지를 나타내며, 숫자는 오프셋을 나타냅니다. 쓰기 작업은 오직 끝에서만 진행되며, 오프셋은 메시지 삽입에 따라 순차적으로 증가. (출처 : https://kafka.apache.org/documentation/)

 - 메시지가 브로커에 저장될 때는 메시지 내용과 함께 오프셋 정보가 저장. 메시지의 오프셋은 메시지를 구분하는 식별자 역할을 하며, 메시지의 삽입에 따라 0부터 꾸준히 증가. 

 - 브로커에 저장되는 메시지들은 파티션 별로 세그먼트(segment)라는 파일로 저장. 예를 들어 토픽 A에 3개의 파티션이 있다면, 각 파티션이 위치한 브로커의 log.dirs 하위에는 해당 파티션의 세그먼트 파일이 존재합니다. 그리고 프로듀서가 파티션으로 발행되는 메시지를 세그먼트 파일에 쓰고, 컨슈머는 이 파일을 읽어감으로써 메시지를 구독합니다.

![kafka_s09](./../../images/tech/kafka_s_04.png)

- 프로듀서는 오직 끝에만 쓰며, 컨슈머는 오프셋을 기준으로 차례차례 읽어나갑니다. (출처 : https://kafka.apache.org/documentation/)

## Zero-copy
- 카프카는 다른 메시징 큐보다 뛰어난 성능을 제공합니다. 그럴 수 있는 이유 중 하나가 제로 카피(Zero-copy) 기술을 사용하기 때문입니다. 제로 카피 기술은 브로커가 세그먼트 파일로부터 메시지를 읽고, 이를 네트워크로 전달하는 과정에서 문맥 교환(context switch)이 없도록 하는 기술.

![kafka_s10](./../../images/tech/kafka_s_05.png)

- 제로 카피가 아닌 경우, 커널 영역과 어플리케이션 영역 간 문맥 교환이 발생.

![kafka_s11](./../../images/tech/kafka_s_06.png)

- 제로 카피인 경우 문맥 교환 없이 커널 영역 안에서만 작업이 이뤄집니다. (출처 : https://developer.ibm.com/articles/j-zerocopy/)
- 카프카는 제로 카피를 통해 더욱 높은 성능을 제공합니다. 다만, 메시지 암호화(SSL)를 설정한 경우에는 메시지 암, 복호화를 위해 어쩔 수 없이 문맥 교환이 발생하므로 제로 카피 기술을 사용불가. 

<details>
  <summary>Exp.</summary>  
  <pre>

### 참조

  </pre>
</details>